{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7aa8107-5cdb-4d4e-8312-4e339f82498b",
   "metadata": {},
   "source": [
    "install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0b0ffc-d40b-4a8f-95ee-87fa4a579cca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install --upgrade tensorflow-hub\n",
    "!pip install tensorflow-text\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fcb8c88-403f-495a-9778-d19923d52828",
   "metadata": {},
   "source": [
    "install required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8bf797-f0d2-4492-b162-13cbd9d560f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "!pip install --upgrade tensorflow-hub\n",
    "!pip install tensorflow-text\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f9c5904-59e8-4eca-9aa1-135ef243ed4c",
   "metadata": {},
   "source": [
    "import required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4090a3-b8ef-4513-bfaa-40c416c4da65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow_text\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow_text import SentencepieceTokenizer\n",
    "import sentencepiece\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "import json\n",
    "import boto3\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "898a6285-5f0e-4bb2-85ad-684666d51876",
   "metadata": {},
   "source": [
    "create directory structure in a format SageMaker Tensorflow serving expects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a2088f-842d-4794-866e-6a26e4b3e728",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir method-embeddings-model-blog\n",
    "!mkdir method-embeddings-model-blog/model\n",
    "!mkdir method-embeddings-model-blog/model/001\n",
    "!mkdir method-embeddings-model-blog/code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8d723d35-fd8b-49d7-a533-75b3430db970",
   "metadata": {},
   "source": [
    "prepare untarred model directory structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca641f5-7ffb-4084-9833-1d5ff5255b96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "export_path = f\"method-embeddings-model-blog\"\n",
    "model_name = \"model\"\n",
    "model_path = f\"{export_path}/{model_name}/001\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "822b2a37-0ba6-464b-9767-5593db260be2",
   "metadata": {},
   "source": [
    "url to download the open-source universal-sentence-encoder-multilingual model from TensorFlow hub. More details here: https://tfhub.dev/google/universal-sentence-encoder-multilingual/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c979cc-1069-4cea-8e34-01a08eb5fa3f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf_model_download_path = \"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3?tf-hub-format=compressed\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583b9674-4fa2-43fa-835e-a09717a33d0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile inference.py\n",
    "\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import requests\n",
    "import boto3\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "\n",
    "def input_handler(data, context):\n",
    "    \"\"\" Pre-process request input before it is sent to TensorFlow Serving REST API\n",
    "    Args:\n",
    "        data (obj): the request data, in format of dict or string\n",
    "        context (Context): an object containing request and configuration details\n",
    "    Returns:\n",
    "        (dict): a JSON-serializable dict that contains request body and headers\n",
    "    \"\"\"\n",
    "    event = data.read().decode('utf-8')\n",
    "    data = json.loads(event)\n",
    "    string_input = data[\"key\"]\n",
    "    array_sentence = sent_tokenize(string_input)\n",
    "    logger.debug(array_sentence)\n",
    "    return json.dumps({\"instances\": [array_sentence]}) \n",
    "\n",
    "\n",
    "def output_handler(data, context):\n",
    "    \"\"\"Post-process TensorFlow Serving output before it is returned to the client.\n",
    "    Args:\n",
    "        data (obj): the TensorFlow serving response\n",
    "        context (Context): an object containing request and configuration details\n",
    "    Returns:\n",
    "        (bytes, string): data to return to client, response content type\n",
    "    \"\"\"\n",
    "    if data.status_code != 200:\n",
    "        raise ValueError(data.content.decode('utf-8'))\n",
    "\n",
    "    response_content_type = context.accept_header\n",
    "    prediction = data.content\n",
    "    return prediction, response_content_type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88604b5b-79ed-4129-8306-bf7d1a56d54b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "boto3\n",
    "pysqlite3\n",
    "requests\n",
    "nltk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36bfda0b-6799-4844-9525-b4c52a6b1437",
   "metadata": {},
   "source": [
    "move relevant files to the untarred directory structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0565f8-7e31-4aac-a940-f61d2aa346b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp inference.py $export_path/code/\n",
    "!cp requirements.txt $export_path/code/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f93ef576-4c0d-4d30-83f4-e1e2314bd118",
   "metadata": {},
   "source": [
    "extract the contents of the model tarball downloaded from the Tensorflow hub to the local directory structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8199c34f-7841-4023-a0eb-b7e31827d4a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!curl -L {tf_model_download_path} | tar -zxvC {model_path}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4abcc0fc-cfea-4636-96ee-aaec28edf817",
   "metadata": {},
   "source": [
    "create a compressed archive of the directory \"method-embeddings-model-blog/\" and saves it as \"model.tar.gz\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183482cb-00c8-4665-9027-0dc5aa60d2c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "!tar -C \"$PWD\" -czf model.tar.gz method-embeddings-model-blog/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef8911c7-a270-4ca3-9a48-b70d7a9f6ea9",
   "metadata": {},
   "source": [
    "upload the \"model.tar.gz\" to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9616970d-4b00-472b-bc4b-59c948adc21a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "time.ctime()\n",
    "from sagemaker.session import Session\n",
    "\n",
    "model_data = Session().upload_data(path=\"model.tar.gz\", key_prefix=\"model\")\n",
    "print(\"model uploaded to: {}\".format(model_data))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ffdcdb1-6796-466d-bfe9-2b9b8d5a324f",
   "metadata": {},
   "source": [
    "create a SageMaker Model that contains references to a model.tar.gz file in S3 containing serialized model data, and a Docker image used to serve predictions with that model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f121e43-255b-4058-b1d2-ae2a0c4d96ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowModel\n",
    "sagemaker_session = sagemaker.Session()\n",
    "sagemaker_role = get_execution_role()\n",
    "framework_version = '2.10'\n",
    "\n",
    "tensorflow_serving_model = TensorFlowModel(model_data=model_data,\n",
    "                                 role=sagemaker_role,\n",
    "                                 framework_version=framework_version,\n",
    "                                 sagemaker_session=sagemaker_session,\n",
    "                                entry_point='inference.py',source_dir=f\"{export_path}/code\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea444c3a-aa16-470c-be93-c28befd8013a",
   "metadata": {},
   "source": [
    "Call deploy on a TensorFlow estimator object to create a SageMaker Endpoint.\n",
    "The SageMaker sdk v2 warning can be safely ignored. The deploy() function uses a default value of update_endpoint=None which triggers the warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cdebde-b204-4c64-b7de-6b3bbfc9b484",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = tensorflow_serving_model.deploy(initial_instance_count=1, instance_type=\"ml.c5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37705b5-7481-4cbe-9b06-eae3bb131b01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(predictor.endpoint_name)\n",
    "endpointName = predictor.endpoint_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43623186-a1df-4631-aabc-6cf514485d64",
   "metadata": {},
   "source": [
    "create a Predictor implementation for inference against TensorFlow Serving endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26774287-f74b-4ec1-b199-aa3474f2153f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "multilingual_predictor = Predictor(endpoint_name=endpointName,\n",
    "                      sagemaker_session=sagemaker.Session(),\n",
    "                      serializer=sagemaker.serializers.JSONSerializer(),\n",
    "                      deserializer=sagemaker.deserializers.JSONDeserializer())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e5c81343-816d-42ad-b8d1-a25d20e6c217",
   "metadata": {},
   "source": [
    "upload the predictor.endpoint_name to the ssm parameter. you can reference this parameter in the CDK code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da10138-f2f7-4faf-82ee-dd8956f92ce4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ssm_client = boto3.client('ssm')\n",
    "ssm_client.put_parameter(\n",
    "    Name='sagemaker-endpoint',\n",
    "    Value=endpointName,\n",
    "    Type='String',Overwrite=True)\n",
    "\n",
    "response = ssm_client.get_parameter(\n",
    "    Name='sagemaker-endpoint'\n",
    ")\n",
    "\n",
    "print(response['Parameter']['Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6683742-f3a9-4237-9a4d-d9ec1e02eb30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
